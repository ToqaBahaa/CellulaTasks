{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHd3hTAV-RBG",
        "outputId": "b5a65c41-9c6e-45c2-efca-7ae96346bc59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Teeth_Dataset\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "\n",
        "# Step 1: Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Define paths\n",
        "zip_path = '/content/drive/MyDrive/TeethDataSet.zip'  # Path to the zip file\n",
        "extract_path = '/content/drive/MyDrive/TeethDataSet'  # Path where files will be extracted\n",
        "\n",
        "# Step 3: Extract the zip file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# Step 4: Verify extraction\n",
        "!ls /content/drive/MyDrive/TeethDataSet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "\n",
        "# Custom transformation functions\n",
        "def resize(image, size):\n",
        "    return image.resize(size, Image.ANTIALIAS)\n",
        "\n",
        "def random_horizontal_flip(image, p=0.5):\n",
        "    if random.random() < p:\n",
        "        return ImageOps.mirror(image)\n",
        "    return image\n",
        "\n",
        "def random_rotation(image, degrees):\n",
        "    return image.rotate(random.uniform(-degrees, degrees))\n",
        "\n",
        "def color_jitter(image, brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2):\n",
        "    # Adjust brightness\n",
        "    brightness_factor = random.uniform(max(0, 1 - brightness), 1 + brightness)\n",
        "    image = ImageEnhance.Brightness(image).enhance(brightness_factor)\n",
        "    # Adjust contrast\n",
        "    contrast_factor = random.uniform(max(0, 1 - contrast), 1 + contrast)\n",
        "    image = ImageEnhance.Contrast(image).enhance(contrast_factor)\n",
        "    # Adjust saturation\n",
        "    saturation_factor = random.uniform(max(0, 1 - saturation), 1 + saturation)\n",
        "    image = ImageEnhance.Color(image).enhance(saturation_factor)\n",
        "    # Adjust hue\n",
        "    hue_factor = random.uniform(-hue, hue)\n",
        "    image = ImageOps.colorize(image.convert('L'), (0, 0, 0), (int(hue_factor*255), int(hue_factor*255), int(hue_factor*255)))\n",
        "    return image\n",
        "\n",
        "def normalize(image, mean, std):\n",
        "    image = np.array(image).astype(np.float32)\n",
        "    image = (image / 255.0 - mean) / std\n",
        "    return torch.tensor(image).permute(2, 0, 1)\n",
        "\n",
        "# Custom Dataset class\n",
        "class TeethDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.transform = transform\n",
        "        self.class_to_idx = self._find_classes(root_dir)\n",
        "        self._make_dataset()\n",
        "\n",
        "    def _find_classes(self, dir):\n",
        "        classes = [d.name for d in os.scandir(dir) if d.is_dir()]\n",
        "        classes.sort()\n",
        "        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
        "        return class_to_idx\n",
        "\n",
        "    def _make_dataset(self):\n",
        "        for cls_name, cls_idx in self.class_to_idx.items():\n",
        "            cls_dir = os.path.join(self.root_dir, cls_name)\n",
        "            for img_name in os.listdir(cls_dir):\n",
        "                if img_name.endswith(('png', 'jpg', 'jpeg')):\n",
        "                    img_path = os.path.join(cls_dir, img_name)\n",
        "                    self.image_paths.append(img_path)\n",
        "                    self.labels.append(cls_idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Custom transform function combining all transformations\n",
        "def custom_transform(image):\n",
        "    image = resize(image, (224, 224))\n",
        "    image = random_horizontal_flip(image)\n",
        "    image = random_rotation(image, 10)\n",
        "    image = color_jitter(image)\n",
        "    image = normalize(image, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    return image\n",
        "\n",
        "# Instantiate the datasets\n",
        "train_dataset = TeethDataset(root_dir='/content/drive/MyDrive/TeethDataSet/Teeth_Dataset/Training', transform=custom_transform)\n",
        "val_dataset = TeethDataset(root_dir='/content/drive/MyDrive/TeethDataSet/Teeth_Dataset/Validation', transform=custom_transform)\n",
        "test_dataset = TeethDataset(root_dir='/content/drive/MyDrive/TeethDataSet/Teeth_Dataset/Testing', transform=lambda x: normalize(resize(x, (224, 224)), mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]))\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "uuxRSuLfBBBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=7):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        # Define the layers of the CNN\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.fc1 = nn.Linear(128 * 28 * 28, 512)  # Adjust input size based on image dimensions\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 128 * 28 * 28)  # Flatten the tensor for the fully connected layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "model = SimpleCNN(num_classes=7)\n"
      ],
      "metadata": {
        "id": "mrbedzZ1CqWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()  # Suitable for classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer with learning rate of 0.001\n"
      ],
      "metadata": {
        "id": "ZVLgh5LiCtLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
        "    model.to(device)  # Ensure model is on the correct device\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)  # Move data to the correct device\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
        "\n",
        "        # Validate the model\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)  # Move data to the correct device\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item() * images.size(0)\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        accuracy = correct / total\n",
        "        print(f'Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "GUkMz1omCu2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    model.to(device)  # Ensure model is on the correct device\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)  # Move data to the correct device\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "IDFbv5Hj2ApS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUbciPLD1luI",
        "outputId": "6f4bb075-3aad-4b61-db90-3aa736a1110e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleCNN(\n",
              "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=100352, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageEnhance, ImageOps\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "\n",
        "# Custom transformation functions\n",
        "def resize(image, size):\n",
        "    return image.resize(size, Image.LANCZOS)\n",
        "\n",
        "def random_horizontal_flip(image, p=0.5):\n",
        "    if random.random() < p:\n",
        "        return ImageOps.mirror(image)\n",
        "    return image\n",
        "\n",
        "def random_rotation(image, degrees):\n",
        "    return image.rotate(random.uniform(-degrees, degrees))\n",
        "\n",
        "def color_jitter(image, brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2):\n",
        "    # Adjust brightness\n",
        "    brightness_factor = random.uniform(max(0, 1 - brightness), 1 + brightness)\n",
        "    image = ImageEnhance.Brightness(image).enhance(brightness_factor)\n",
        "    # Adjust contrast\n",
        "    contrast_factor = random.uniform(max(0, 1 - contrast), 1 + contrast)\n",
        "    image = ImageEnhance.Contrast(image).enhance(contrast_factor)\n",
        "    # Adjust saturation\n",
        "    saturation_factor = random.uniform(max(0, 1 - saturation), 1 + saturation)\n",
        "    image = ImageEnhance.Color(image).enhance(saturation_factor)\n",
        "    # Adjust hue\n",
        "    hue_factor = random.uniform(-hue, hue)\n",
        "    image = ImageOps.colorize(image.convert('L'), (0, 0, 0), (int(hue_factor*255), int(hue_factor*255), int(hue_factor*255)))\n",
        "    return image\n",
        "\n",
        "def normalize(image, mean, std):\n",
        "    image = np.array(image).astype(np.float32)\n",
        "    image = (image / 255.0 - mean) / std\n",
        "    return torch.tensor(image).permute(2, 0, 1)\n",
        "\n",
        "# Custom Dataset class\n",
        "class TeethDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.transform = transform\n",
        "        self.class_to_idx = self._find_classes(root_dir)\n",
        "        self._make_dataset()\n",
        "\n",
        "    def _find_classes(self, dir):\n",
        "        classes = [d.name for d in os.scandir(dir) if d.is_dir()]\n",
        "        classes.sort()\n",
        "        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
        "        return class_to_idx\n",
        "\n",
        "    def _make_dataset(self):\n",
        "        for cls_name, cls_idx in self.class_to_idx.items():\n",
        "            cls_dir = os.path.join(self.root_dir, cls_name)\n",
        "            for img_name in os.listdir(cls_dir):\n",
        "                if img_name.endswith(('png', 'jpg', 'jpeg')):\n",
        "                    img_path = os.path.join(cls_dir, img_name)\n",
        "                    self.image_paths.append(img_path)\n",
        "                    self.labels.append(cls_idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Custom transform function combining all transformations\n",
        "def custom_transform(image):\n",
        "    image = resize(image, (224, 224))\n",
        "    image = random_horizontal_flip(image)\n",
        "    image = random_rotation(image, 10)\n",
        "    image = color_jitter(image)\n",
        "    image = normalize(image, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    return image\n",
        "\n",
        "# Instantiate the datasets\n",
        "train_dataset = TeethDataset(root_dir='/content/drive/MyDrive/TeethDataSet/Teeth_Dataset/Training', transform=custom_transform)\n",
        "val_dataset = TeethDataset(root_dir='/content/drive/MyDrive/TeethDataSet/Teeth_Dataset/Validation', transform=custom_transform)\n",
        "test_dataset = TeethDataset(root_dir='/content/drive/MyDrive/TeethDataSet/Teeth_Dataset/Testing', transform=lambda x: normalize(resize(x, (224, 224)), mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]))\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "dBVFAj7F1pfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(image, mean, std):\n",
        "    image = np.array(image).astype(np.float32)  # Ensure the image is float32\n",
        "    image = (image / 255.0 - mean) / std\n",
        "    return torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)  # Ensure tensor is float32\n"
      ],
      "metadata": {
        "id": "azKfOFBZ2mxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device, dtype=torch.float32), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
        "\n",
        "        # Validate the model\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device, dtype=torch.float32), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item() * images.size(0)\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        accuracy = correct / total\n",
        "        print(f'Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "4CI-Wl-V2xa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device, dtype=torch.float32), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "cf8pN3ln2zj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate_model(model, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mBVUNgI22CI",
        "outputId": "04bb04ff-350e-4eb7-de3f-89c8c0e6a24a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 2.0464\n",
            "Validation Loss: 1.9348, Accuracy: 0.1751\n",
            "Epoch 2/10, Loss: 1.9371\n",
            "Validation Loss: 1.9333, Accuracy: 0.1722\n",
            "Epoch 3/10, Loss: 1.9326\n",
            "Validation Loss: 1.9355, Accuracy: 0.1751\n",
            "Epoch 4/10, Loss: 1.9329\n",
            "Validation Loss: 1.9303, Accuracy: 0.1751\n",
            "Epoch 5/10, Loss: 1.9324\n",
            "Validation Loss: 1.9447, Accuracy: 0.1751\n",
            "Epoch 6/10, Loss: 1.9338\n",
            "Validation Loss: 1.9313, Accuracy: 0.1751\n",
            "Epoch 7/10, Loss: 1.9327\n",
            "Validation Loss: 1.9333, Accuracy: 0.1751\n",
            "Epoch 8/10, Loss: 1.9367\n",
            "Validation Loss: 1.9312, Accuracy: 0.1751\n",
            "Epoch 9/10, Loss: 1.9336\n",
            "Validation Loss: 1.9310, Accuracy: 0.1751\n",
            "Epoch 10/10, Loss: 1.9310\n",
            "Validation Loss: 1.9298, Accuracy: 0.1751\n",
            "Test Accuracy: 0.1340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "def predict_image(model, image_path, transform):\n",
        "    # Load and preprocess the image\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "    # Move the image to the same device as the model (e.g., GPU if available)\n",
        "    image = image.to(device)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Predict the class\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "\n",
        "    return predicted.item()\n",
        "\n",
        "# Example usage:\n",
        "image_path = '/content/drive/MyDrive/TeethDataSet/Teeth_Dataset/Testing/MC/mc_1202.jpg'  # Replace with your image path\n",
        "predicted_class = predict_image(model, image_path, transform=custom_transform)\n",
        "print(f'Predicted class: {predicted_class}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAFZhruRRpwt",
        "outputId": "10c32815-81a9-45f2-bb9e-35ada4160b10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "train_labels = [label for _, label in train_dataset]\n",
        "class_distribution = Counter(train_labels)\n",
        "print(\"Class distribution in training data:\", class_distribution)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VwFGfPOTTvg",
        "outputId": "310ac627-a5e4-4d64-a8a4-fd3349ae1fc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution in training data: Counter({3: 540, 5: 540, 0: 480, 1: 450, 6: 393, 2: 360, 4: 324})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reverse the class_to_idx dictionary\n",
        "idx_to_class = {v: k for k, v in train_dataset.class_to_idx.items()}\n",
        "\n",
        "# Get the class name for the predicted class (5 in this case)\n",
        "predicted_class_name = idx_to_class[5]\n",
        "print(f'Class 5 corresponds to: {predicted_class_name}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QglxJXVLSpAu",
        "outputId": "df8c8e73-83b6-48d4-d8ab-c4100b9d0ac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 5 corresponds to: OLP\n"
          ]
        }
      ]
    }
  ]
}